Müsadenizle size bazı şeyler göstermek istiyorum.
(Video) Kız: Tamam, burada yatağın üzerinde oturan bir kedi var. Çocuk fili okşuyor. Buradaki insanlar uçağa gidiyorlar. Bu büyük bir uçak.
Fei-Fei Li: Üç yaşında küçük bir kız çocuğu fotoğraflarda ne gördüğünü anlatıyor. Henüz, dünya hakkında öğrenmesi gereken çok şey var fakat çok önemli bir alanda uzman olmuş bile: gördüklerini anlamlandırma. Toplumumuz teknolojik olarak her zamankinden daha fazla ilerlemiş durumda. İnsanları aya gönderiyoruz, bizimle konuşabilen ya da radyo kanallarını sadece sevdiğimiz müzikleri çalması için düzenleyebilen telefonlar yapıyoruz. En gelişmiş makinelerimiz ve bilgisayarlarımız hâlâ bu özelliği elde etmeye çalışıyorlar. Bugün, bilgisayar görme yetisi üzerine yapılan ileri düzeydeki araştırmalarımızın işleyişi hakkında size bilgi vermek için buradayım. Bilgisayar biliminde, en önde ve devrim niteliğinde olan teknolojik gelişmelerden biri.
Evet, kendini sürebilen araçların prototiplerine sahibiz, fakat akıllı görme yetisine sahip olmadan, üzerinden geçilebilecek buruşmuş bir kağıt torba ile sakınılması gereken aynı boyuttaki bir kaya arasındaki farkı söyleyebilmeleri mümkün değil. Mükemmel çözünürlükte kameralar yapmamıza rağmen, görebilmelerini sağlayamamıştık. İnsansız hava araçları koca bir araziyi uçabilirler, ama yağmur ormanlarındaki değişimleri izlememize yardımcı olabilecek düzeyde yeterli bir görüş kabiliyetine sahip değiller. Güvenlik kameraları her yerde, fakat bir çocuk havuzda boğuluyorken bizi uyaramıyorlar. Fotoğraf ve videolar gündelik hayatın bir parçası haline geliyorlar. Herhangi bir insan veya bazı grupların görme umuduyla hızlı bir şekilde çoğalıyorlar, buradaki TED konuşmaları ile sizler ve ben de buna katkı sağlıyoruz. En iyi yazılımımız hala bu devasa içeriği anlamaya ve yönetmeye çabalıyor. Başka bir anlamda, toplumun tamamı olarak büyük bir görme kaybına sahibiz çünkü en iyi makinelerimiz hala göremiyorlar.
"Neden bu kadar zor ki bu?" diye soracaksınız. Kameralar burada da olduğu gibi fotoğraf çekebilirler, ışığın iki boyutlu sayı dizilerine çevrilmiş hali ile, ki bunlara pikseller diyoruz. Fakat burada sadece ölü sayılar bulunmakta. Kendi içlerinde herhangi bir anlam taşımıyorlar. Nasıl ki duymak ile dinlemek aynı anlama gelmiyorsa fotoğraf çekmek ile görmek de aynı şeyi ifade etmiyor. Görmek derken ciddi manada "anlamayı" kastediyoruz. Aslında, bu yetiye sahip olabilmemiz tabiat ananın 540 milyon yılını aldı. Bu çabanın çoğu, beynin görsel işleme bölümünün gelişimine gitti sadece gözlerin kendisine değil. Yani görmek gözlerde başlıyor, ama asıl olarak beynin bir bölümünde anlam kazanıyor.
15 sene önce, Caltech'deki doktorama başladığımda ve sonra Stanford Görsel Laboratuvarını yönlendirdiğimde mentorlerim, iş ortaklarım ve öğrencilerimle birlikte bilgisayarlara görmeyi öğretmek için çalışıyorduk. Araştırma alanımız bilgisayar görme yetisi ve makine öğrenimi olarak anılıyordu. Yapay zeka bölümünün genel bir dalı olarak geçiyordu. Nihayetinde, makinelere tıpkı bizim gibi görebilmelerini öğretmek istedik, nesnelerin isimlendirilmesi, insanların tanımlanması, 3B geometrileri tahmin ilişkileri anlama, duygular, olaylar ve şiddet. Şu anda insanların, yerlerin ve eşyaların bütün hikayesini gözler önüne serip beraber dokuyalım.
Bu amaca doğru atılacak ilk adım bilgisayara gördüğü şeyleri öğretmek, sanal dünyanın yapı taşı bu. Basit anlamda bu öğretme sürecini bi hayal edin, bilgisayara belirli bir nesnenin ya da bir kedinin diyelim deneme amaçlı resimlerini göstermek gibi ve bu resimlerden öğrenilmiş bir model tasarlamayı. Bu ne kadar zor olabilir ki? Sonuç olarak, bir kedi sadece şekillerin ve renklerin bir derlemesi ve bu ilk zamanlarda yaptığımız nesne modellemesi. Algoritmasını sayısal bir dille bilgisayara öğretmemiz gerekiyordu bu kedi yuvarak bir yüze, dolgun bir vücuda iki noktada kulaklara ve uzun bir kuyruğa sahip her şey yolunda gibi. Peki, ya bu kedi? (Gülüşmeler) Hepsi iç içe. Bu nesne için için farklı bir şekil ve farklı bir bakış açısı eklemeniz gerek. Peki ya kediler gizlenirse? Bu absürd kedilere ne demeli? Şimdi ne demek istediğimi anladınız. Evdeki kedi gibi basit bir şey için bile sonsuz çeşitlilikte nesne modellemesi yapmak mümkün ve bu sadece bir nesne.
Yaklaşık sekiz yıl önce, oldukça basit ama yoğun bir gözlem fikrimi değiştirdi. Hiç kimse bir çocuğa nasıl görebileceğini öğretmez, özellikle de erken yaşlarda. Gerçek dünya tecrübeleri ve örnekleriyle öğrenirler bunu. Bir çocuğun gözlerini düşünecek olursanız sanki bir çift biyolojik kameraymış gibi, yaklaşık her 200 milisaniyede bir fotoğraf çekerler, göz hareketinden oluşmuş ortalama bir zaman dilimi. Yani üç yaşında bir çocuk, gerçek hayatta yüz milyonlarca fotoğraf görmüş olacak. Bu oldukça fazla deneme örneği. Sadece daha iyi algoritmalara odaklanmak yerine, sezilerim algoritmalara bir tür eğitici veri vermek üzerineydi, tıpkı bir çocuğa sayıca ve kalitece deneyimleri yoluyla verilmiş gibi.
Bunu anlayınca, bir tür veri havuzuna sahip olduğumuz resimlerden daha fazla, hatta binlerce kat daha fazla ihtiyacımız olduğunu biliyorduk. Princeton Üniversitesinden Prof. Kai Li ile birlikte 2007 senesinde ImageNet projesini başlattık. Şanslıyız ki başımızın üzerine bir kamera alıp yıllarca beklememize gerek kalmadı. İnternete başvurduk. İnsanların oluşturduğu en büyük resim definesi. Yaklaşık bir milyar resim indirdik ve crowdsourcing teknolojisini kullandık. Resimleri tanımlamada bize yardımcı olmada Amazon Mechanical Turk platformu gibi. ImageNet, Amazon Mechanical Turk çalışanlarına işveren en büyük kurumlardan biri oldu. Dünya genelinde 167 ülkeden neredeyse 50,000 çalışan yaklaşık bir milyar resmi eleyip, sınıflandırma ve tanımlamada bize yardımcı oldu. Bu çaba, erken gelişim dönemindeki bir çocuğun algıladığı görüntülerin sadece belli bir bölümünü elde edebilmemiz içindi.
Nihayet, bilgisayar algoritmalarını eğitmek için big datanın kullanılması fikri şu anda mümkün hale geldi, fakat 2007 senesine dönersek, bu mümkün değildi. Bu yolculukta uzun bir süre tam anlamıyla kendi başımızaydık. Samimi bazı arkadaşlarım kadrom için daha kullanışlı şeyler yapmamı tavsiye ettiler, ve aynı zamanda araştırma fonu oluşturmak için durmaksızın çabalıyorduk. Hatta, master öğrencilerime ImageNet fonu için kuru temizleme mağazamı tekrar açma konusunda şaka yapıyordum. Üniversite yıllarımda bu şekilde geçiniyordum.
Sonra devam ettik. 2009 senesinde, ImageNet projesi her gün ingilizce kelimelerle 22,000 nesne ve eşya sınıfı ile 15 milyonluk bir resim veritabanına ulaştı. Sayı ve kalite olarak, emsalsiz bir ölçekti bu. Örneğin, kedi kategorisinde, görünüş ve poz ile evcil ve yaban türlerinin tümüyle 62 binden fazla kedi bulunmakta. Bunları ImageNet olarak toparladığımızdan heyecanlıydık ve sonra bütün dünya araştırmalarında bunlardan faydalanılsın istedik, bu yüzden TED fashion'da bütün veri havuzumuzu global araştırma topluluklarına ücretsiz bir şekilde açtık. (Alkış)
Artık, bilgisayarımızın beynini besleyecek veriye sahibiz, algoritmaların kendilerine dönecek kadar da hazırız. ImageNet projesinin sağladığı bilgi zenginliği, sonunda "evrişimli sinirsel ağ" olarak ifade edilen makine öğrenme algoritmalarının özel bir sınıfıyla mükemmel bir şekilde eşleşmişti, öncülüğünü Kunihiko Fukushima, Geoff Hinton ve Yann LeCun'un yaptığı 1970 ve 80'lerin öncesindeki bir alan. Beyinde meydana gelen milyarlarca yüksek bağlantılı sinirler gibi, sinir ağının basit bir çalışma birimine "nöron benzeri" düğümü deniyor. Başka düğümlerden girdi alıyorlar ve diğer düğümlere gönderiyorlar. Dahası, bu yüzbinlerce hatta milyonlarca düğüm hiyerarşik tabakalarla düzenleniyorlar tıpkı beyin gibi. Normal bir sinir ağında nesne tanıma modelimizi eğitmek için, 24 milyon düğüm, 140 milyon değişken, ve 15 milyar bağlantı kullandık. Bu muazzam bir modeldi. ImageNet'den elde edilen büyük veri ile oldukça muazzam bir modeli eğitmek için kullanılan modern CPU ve GPU'lar sayesinde evrişimli sinirsel ağ hiçbirimizin hayal edemeyeceği bir şekilde gelişti. Nesne tanımlamada etkileyeci yeni sonuçlar üretmek için başarılı bir mimari olmaya başladı. Bu bilgisayarın bize söylediği, bu fotoğrafta bir kedinin olduğu ve kedinin nerede olduğu. Elbette orada kedilerden daha fazlası var, burada ise bilgisayar algoritmasının bize söylediği resimde bir çocuk ile oyuncak bir ayının; bir köpeğin, bir kişinin ve arkaplanda küçük bir uçurtmanın; ya da çok karışık bir resimin bir adam, bir kaykay, korkuluklar, lamba direği v.b. gibi şeyler olduğu. Bazen, bilgisayar ne gördüğü hakkında emin olamayınca çok fazla düşünmek yerine yeterince mantıklı bir cevap vermesini öğrettik, tıpkı bizim yapacağımız gibi fakat başka zamanlarda bilgisayar algoritmamız bize dikkate değer şeyler tam olarak nesnelerin ne olduğunu marka, model ve üretim yılı gibi şeyleri söylüyor.
Bu algoritmayı Google Sokak Görüntüleme ile yüzlerce Amerika şehrinden alınmış resimlere uyguladık ve gerçekten ilginç şeyler öğrendik: öncelikle, hepimizin bildiği gibi araç fiyatlarının aile gelir düzeyiyle doğrudan ilişkili olduğunu teyit etti fakat ilginçtir ki, araç fiyatları aynı zamanda şehirdeki suç oranları ya da posta kodlarından oy verme alanları ile de bağlantılı.
Peki biraz düşünün, bu oldu mu? Bilgisayar henüz insan kabiliyetlerine erişebildi mi hatta daha üstün geldi mi ? Hayır, o kadar hızlı değil. Şu ana dek, sadece bilgisayara nesneleri görmesini öğrettik. Bu küçük bir çocuğun bir kaç kelime söylemesini öğrenmesi gibi bir sey. İnanılmaz bir başarıdır bu, fakat bu sadece ilk adımdır. Sonrasında, başka bir gelişimsel dönüm noktası açığa çıkar, ve çocuk cümlelerle iletişim kurmaya başlar. Yani, "bu resimdeki bir kedidir" demek yerine dinlediğiniz gibi küçük kız bize "bu yatağın üzerinde uzanan bir kedidir" diyor
Bilgisayarı resimleri görmek ve cümle kurmak için eğitmek, big data ile makine öğrenim algoritmasının beraberliği için bir adım daha atılmalı. Şimdilik, bilgisayarın her resimden insanlar tarafından oluşturulmuş kadar iyi cümleler öğrenmesi gerek. Beynin görsellik ve dili bütünleştirdiği gibi, biz de ufak görsel parçacıklar gibi görsel şeylerle cümlelerdeki kelime ve ifadeleri birleştirecek bir model geliştirdik.
Yaklaşık dört ay önce, sonunda bütün bunları bağladık ve bir fotoğrafı ilk kez gördüğünde bir insan gibi cümle kurabilme yeteneğine sahip ilk bilgisayar görme modelinden bir tane yaptık. Şu anda, bilgisayarın konuşmamızın başında küçük kızın gördüğü resimleri gördüğünde neler söylediğini size göstermeye hazırım.
(Video) Bilgisayar: Bir adam filin yanında duruyor. Geniş bir uçak, uçak pistinin üstünde oturuyor.
FFL: Tabii, hala sıkı bir şekilde algoritmamızı geliştirmek için çalışıyoruz ve henüz öğreneceği çok sey var. (Alkış)
Bilgisayar henüz hatalar yapmakta.
Bilgisayar: Bir kedi battaniyenin içinde yatakta uzanıyor.
FFL: Tabii, oldukça fazla kedi gördüğünden herşeyin kediye benzeyebileceğini düşünüyor.
Bilgisayar: Genç erkek bir beysbol sopasını tutuyor. (Gülüşmeler)
FFL: Ya da, henüz bir diş fırçası görmemişse, beysbol sopasıyla karıştırıyor
Bilgisayar: Bir adam binanın kenarından atını sokak aşağı sürüyor. (Gülüşmeler)
FFL: Henüz bilgisayarlara Sanat 101 dersini öğretmedik.
Bilgisayar: Bir zebra otlukların içinde duruyor.
FFL: Ve henüz doğanın büyüleci güzelliğini takdir etmeyi bizim gibi öğrenmedi.
Uzun bir yolculuktu. Sıfırdan üç yaşına getirmek oldukça zordu. Asıl zor olan üç yaşından on üç yaş ve daha ötesine götürebilmek. Size bu resmi tekrar hatırlatmak istiyorum, çocuk ve kekin olduğu. Şu ana dek, bilgisayara nesneleri görebilmesini hatta gördüğü resimden küçük bir hikaye anlatmasını bile öğrettik.
Bilgisayar: Biri yaş pastanın olduğu masada oturuyor.
FFL: Fakat bu resimde sadece bir kişi ve pastadan daha fazlası var. Bilgisayarın göremediği şey, onun sadece Paskalya süresince servis edilen özel bir İtalyan pastası olduğu. Çocuk, babası tarafından Sidney gezisinden sonra kendisine hediye edilen en sevdiği tişörtünü giyiyor, hepimiz onun nasıl mutlu olduğunu ve şu anda kafasından geçenleri söyleyebiliriz.
Bu benim oğlum Leo. Görsel zeka araştırmalarımda, durmaksızın Leo'yu ve içinde yaşayacağı geleceği düşünüyorum. Makineler görebildiğinde, doktor ve hemşireler, tanı koymak ve hastalarla ilgilenmek için ek olarak yorulmayan göz çiftlerine sahip olacaklar. Arabalar yollarda daha güvenli daha akıllı bir şekilde gidecek. Robotlar, sadece insanlar değil, enkaz bölgelerinde tutsak ve yaralıları kurtarmada bizimle göğüs gerecekler. Yeni tür, daha iyi malzemeler bulacak ve makinelerin yardımıyla, görünmeyen sınırları keşfedeceğiz.
Azar azar, makinelere görme yetisini veriyoruz. Önce, biz onlara görmeyi öğretiyoruz. Sonra, onlar daha iyi görebilmemiz için bize yardım ediyor. Öncelikle, dünyamızı keşfetmek ve düşünmek için gözlerimiz sadece insan gözleri olmayacak. Makineleri sadece zekaları için kullanmıyor, aynı zamanda hayal bile edemeyeceğimiz bir şekilde onlarla iş birliği yapıyoruz.
Benim araştırmam bu: bilgisayarlara görsel zekayı vermek ve Leo için, dünya için daha iyi bir gelecek oluşturmak.
Teşekkürler.
(Alkış)